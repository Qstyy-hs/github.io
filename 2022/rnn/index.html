<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

    
    <title>Êï∞Â≠¶Âª∫Ê®°-RNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªú | Kmoon</title>

    <meta name="description" content="Âü∫‰∫éRNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÁöÑË∞£Ë®ÄÊ£ÄÊµãÁ≥ªÁªü

### ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ì
import json
import os
import random
import re
from multiprocessing import cpu_count
import numpy as np
import paddle
import paddle.fluid as fluid
paddle.enable_static()
import matplotlib.pyplot as plt

### ÂéªÈô§Â≠óÁ¨¶‰∏≤ÁöÑÊ†áÁÇπÁ¨¶Âè∑
r=&#39;[‚Äô!&#34;\&#39;()+,-./:;&amp;lt;=&amp;gt;?@[\\]`{|}~\n„ÄÇÔºÅÔºå]+&#39;
def removeP">
    <meta name="keywords" content="">

    

    <meta property="og:locale" content="cn" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content= "Êï∞Â≠¶Âª∫Ê®°-RNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªú | Kmoon"  />
    <meta property="og:description" content= "Âü∫‰∫éRNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÁöÑË∞£Ë®ÄÊ£ÄÊµãÁ≥ªÁªü

### ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ì
import json
import os
import random
import re
from multiprocessing import cpu_count
import numpy as np
import paddle
import paddle.fluid as fluid
paddle.enable_static()
import matplotlib.pyplot as plt

### ÂéªÈô§Â≠óÁ¨¶‰∏≤ÁöÑÊ†áÁÇπÁ¨¶Âè∑
r=&#39;[‚Äô!&#34;\&#39;()+,-./:;&amp;lt;=&amp;gt;?@[\\]`{|}~\n„ÄÇÔºÅÔºå]+&#39;
def removeP" />
    <meta property="og:url" content="https://www.kmoon.fun/2022/rnn/index.html" />
    <meta property="og:site_name" content="" />
    <meta property="article:author" content="Kmoon" />
    <meta property="article:publisher" content="" />
    <meta property="og:description" content="Âü∫‰∫éRNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÁöÑË∞£Ë®ÄÊ£ÄÊµãÁ≥ªÁªü

### ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ì
import json
import os
import random
import re
from multiprocessing import cpu_count
import numpy as np
import paddle
import paddle.fluid as fluid
paddle.enable_static()
import matplotlib.pyplot as plt

### ÂéªÈô§Â≠óÁ¨¶‰∏≤ÁöÑÊ†áÁÇπÁ¨¶Âè∑
r=&#39;[‚Äô!&#34;\&#39;()+,-./:;&amp;lt;=&amp;gt;?@[\\]`{|}~\n„ÄÇÔºÅÔºå]+&#39;
def removeP" />
    <meta name="twitter:title" content="Êï∞Â≠¶Âª∫Ê®°-RNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªú | Kmoon"/>
    <meta name="twitter:description" content="Âü∫‰∫éRNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÁöÑË∞£Ë®ÄÊ£ÄÊµãÁ≥ªÁªü

### ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ì
import json
import os
import random
import re
from multiprocessing import cpu_count
import numpy as np
import paddle
import paddle.fluid as fluid
paddle.enable_static()
import matplotlib.pyplot as plt

### ÂéªÈô§Â≠óÁ¨¶‰∏≤ÁöÑÊ†áÁÇπÁ¨¶Âè∑
r=&#39;[‚Äô!&#34;\&#39;()+,-./:;&amp;lt;=&amp;gt;?@[\\]`{|}~\n„ÄÇÔºÅÔºå]+&#39;
def removeP"/>
    <script type="application/ld+json">
        {
            "description": "Âü∫‰∫éRNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÁöÑË∞£Ë®ÄÊ£ÄÊµãÁ≥ªÁªü

### ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ì
import json
import os
import random
import re
from multiprocessing import cpu_count
import numpy as np
import paddle
import paddle.fluid as fluid
paddle.enable_static()
import matplotlib.pyplot as plt

### ÂéªÈô§Â≠óÁ¨¶‰∏≤ÁöÑÊ†áÁÇπÁ¨¶Âè∑
r=&#39;[‚Äô!&#34;\&#39;()+,-./:;&amp;lt;=&amp;gt;?@[\\]`{|}~\n„ÄÇÔºÅÔºå]+&#39;
def removeP",
            "author": { "@type": "Person", "name": "Kmoon" },
            "@type": "BlogPosting",
            "url": "https://www.kmoon.fun/2022/rnn/index.html",
            "publisher": {
            "@type": "Organization",
            "logo": {
                "@type": "ImageObject",
                "url": "https://www.kmoon.fun/image/avatar.png"
            },
            "name": "Kmoon"
            },
            "headline": "Êï∞Â≠¶Âª∫Ê®°-RNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªú | Kmoon",
            "datePublished": "2022-08-11T07:46:47.000Z",
            "mainEntityOfPage": {
                "@type": "WebPage",
                "@id": "https://www.kmoon.fun/2022/rnn/index.html"
            },
            "@context": "http://schema.org"
        }
    </script>




    
    <meta name="google-site-verification" content="XXX" />
    

    
    <meta property="algolia:search" data-application-id="8Z51BHYAUH" data-api-key="dbc9dafd607e95ea5aa312369120eabd" data-index-name="kmoon_blog">
    

    

    

    
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåúÔ∏è</text></svg>">
    

    

    

    
<link rel="stylesheet" href="/dist/build.css?v=1654266144177.css">


    
<link rel="stylesheet" href="/dist/custom.css?v=1654266144177.css">


    <script>
        window.isPost = true
        window.aomori = {
            
            
            valine: {
                enable: true,
                appId: "jEGcWPtFOBkynV3AUJIKLr8T-gzGzoHsz",
                appKey: "PM600NTeCMYW8HIwM4j0YzAM",
                placeholder: "Hello World!",
                avatar: "",
                pageSize: "10",
                lang: "zh-CN",
                visitor: false,
                highlight: false,
                recordIP: false,
                emojiCDN: "",
                enableQQ: false,
                requiredFields: []
            },
            
            
        }
        window.aomori_logo_typed_animated = true
        window.aomori_search_algolia = true

    </script>

<meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Kmoon" type="application/atom+xml">
</head>

<body>

    <div class="container">
    <header class="header">
        <div class="header-type">
            
            <div class="header-type-avatar avatar avatar-sm">
                <img src="/image/avatar.png" alt="Kmoon">
            </div>
            
            <div class="header-type-inner">
                
                    <div id="typed-strings" style="display:none">
                        <p>Kmoon</p>
                    </div>
                    <a class="header-type-title" id="typed" href="/"></a>
                
    
                
            </div>
        </div>
        <div class="header-menu">
            <div class="header-menu-inner">
                
                <a href="/">‰∏ªÈ°µ</a>
                
                <a href="/archives">ÂΩíÊ°£</a>
                
                <a href="/2022/10/about/">ÂÖ≥‰∫é</a>
                
                <a href="/about">Ê∑±Ê∏ä</a>
                
                <a href="/">Wiki</a>
                
            </div>
            <div class="header-menu-social">
                
    <a class="social" target="_blank" href="https://github.com/kmoonn/">
        <ion-icon name="logo-github"></ion-icon>
    </a>

    <a class="social" target="_blank" href="">
        <ion-icon name="logo-wechat"></ion-icon>
    </a>

            </div>
        </div>

        <div class="header-menu-mobile">
            <div class="header-menu-mobile-inner" id="mobile-menu-open">
                <i class="icon icon-menu"></i>
            </div>
        </div>
    </header>

    <div class="header-menu-mobile-menu">
        <div class="header-menu-mobile-menu-bg"></div>
        <div class="header-menu-mobile-menu-wrap">
            <div class="header-menu-mobile-menu-inner">
                <div class="header-menu-mobile-menu-close" id="mobile-menu-close">
                    <i class="icon icon-cross"></i>
                </div>
                <div class="header-menu-mobile-menu-list">
                    
                    <a href="/">‰∏ªÈ°µ</a>
                    
                    <a href="/archives">ÂΩíÊ°£</a>
                    
                    <a href="/2022/10/about/">ÂÖ≥‰∫é</a>
                    
                    <a href="/about">Ê∑±Ê∏ä</a>
                    
                    <a href="/">Wiki</a>
                    
                </div>
            </div>
        </div>
    </div>

</div>

    <div class="container">
        <div class="main">
            <section class="inner">
                <section class="inner-main">
                    <div class="post">
    <article id="post-cl9o8n477003n0wvm5ncjbr8u" class="article article-type-post" itemscope
    itemprop="blogPost">

    <div class="article-inner">

        
          
        
        
        

        
        <header class="article-header">
            
  
    <h1 class="article-title" itemprop="name">
      Êï∞Â≠¶Âª∫Ê®°-RNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªú
    </h1>
  

        </header>
        

        <div class="article-more-info article-more-info-post hairline">

            <div class="article-date">
  <time datetime="2022-08-11T07:46:47.000Z" itemprop="datePublished">2022-08-11</time>
</div>

            
            <div class="article-category">
                <a class="article-category-link" href="/categories/Math/">Math</a>
            </div>
            

            
            <div class="article-tag">
                <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" rel="tag">Êï∞Â≠¶Âª∫Ê®°</a></li></ul>
            </div>
            

            
            <div class="article-busuanzi">
                <span id="busuanzi_value_page_pv">N</span> ‰∫∫ÁúãËøá
            </div>
            

        </div>

        <div class="article-entry post-inner-html hairline" itemprop="articleBody">
            <p>Âü∫‰∫éRNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÁöÑË∞£Ë®ÄÊ£ÄÊµãÁ≥ªÁªü</p>
<span id="more"></span>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">### ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ì</span>
<span class="token keyword">import</span> json
<span class="token keyword">import</span> os
<span class="token keyword">import</span> random
<span class="token keyword">import</span> re
<span class="token keyword">from</span> multiprocessing <span class="token keyword">import</span> cpu_count
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> paddle
<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>fluid <span class="token keyword">as</span> fluid
paddle<span class="token punctuation">.</span>enable_static<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment">### ÂéªÈô§Â≠óÁ¨¶‰∏≤ÁöÑÊ†áÁÇπÁ¨¶Âè∑</span>
r<span class="token operator">=</span><span class="token string">'[‚Äô!"\'()+,-./:;&lt;=&gt;?@[\\]`{|}~\n„ÄÇÔºÅÔºå]+'</span>
<span class="token keyword">def</span> <span class="token function">removePunctuation</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    line<span class="token operator">=</span>re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">,</span>text<span class="token punctuation">)</span>
    <span class="token keyword">return</span> line

<span class="token comment">### ÊèêÂèñÁâπÊÆäÁ¨¶Âè∑</span>
s<span class="token operator">=</span><span class="token string">'‚Ä¶@#^&amp;*'</span>
<span class="token keyword">def</span> <span class="token function">changePunctuation</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> s<span class="token punctuation">:</span>
        <span class="token keyword">if</span> i <span class="token keyword">in</span> text<span class="token punctuation">:</span>
            text<span class="token operator">=</span>text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>s<span class="token punctuation">,</span><span class="token string">' '</span><span class="token operator">+</span>s<span class="token operator">+</span><span class="token string">' '</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> text
<span class="token comment">### Êï∞ÊçÆÂ≠óÂÖ∏Á¥¢ÂºïÂ≠òÂú®Âà§Êñ≠</span>
<span class="token keyword">def</span> <span class="token function">judge</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">,</span><span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">str</span> <span class="token keyword">in</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">str</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">""</span>
    
<span class="token comment">### ÂàÜÂà´ÁªüËÆ°Ë∞£Ë®ÄÊï∞ÊçÆ‰∏éÁúüÊñ∞ÈóªÊï∞ÊçÆÁöÑÊÄªÊï∞</span>
rumor_num <span class="token operator">=</span> <span class="token number">0</span>
non_rumor_num <span class="token operator">=</span> <span class="token number">0</span>

all_rumor_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
all_non_rumor_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment">### Ë∞£Ë®ÄÊ†áÁ≠æ‰∏∫0ÔºåÁúüÊñ∞ÈóªÊ†áÁ≠æ‰∏∫1</span>
rumor_label <span class="token operator">=</span> <span class="token string">"0"</span>
non_rumor_label <span class="token operator">=</span> <span class="token string">"1"</span>

dicts_Fake<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token comment">#Â£∞ÊòéË∞£Ë®ÄÂ≠óÂÖ∏</span>
dicts_Real<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token comment">#Â£∞ÊòéÁúüÊñ∞ÈóªÂ≠óÂÖ∏</span>
road_Fake<span class="token operator">=</span><span class="token string">"Ë∞£Ë®Ä\PolitiFact_Fake_"</span>     <span class="token comment">#Ë∞£Ë®ÄÊñá‰ª∂Â§πË∑ØÂæÑ</span>
road_Real<span class="token operator">=</span><span class="token string">"ÁúüÊñ∞Èóª\PolitiFact_Real_"</span>    <span class="token comment">#ÁúüÊñ∞ÈóªÊñá‰ª∂Â§πË∑ØÂæÑ</span>

<span class="token comment">### ÂÆö‰πâjsonËΩ¨Â≠óÂÖ∏ÂáΩÊï∞</span>
<span class="token keyword">def</span> <span class="token function">to_dict</span><span class="token punctuation">(</span>road<span class="token punctuation">,</span>dicts<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">111</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        filename<span class="token operator">=</span><span class="token string">r"C:\\Users\34538\Desktop\EÈ¢òÈôÑ‰ª∂\ÈôÑ‰ª∂1.ËÆ≠ÁªÉÊï∞ÊçÆ\\"</span><span class="token operator">+</span>road<span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"-Webpage.json"</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            txt<span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
            dicts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>txt

<span class="token comment">### ÊûÑÂª∫Ë∞£Ë®ÄÂíåÁúüÊñ∞ÈóªÂ≠óÂÖ∏</span>
to_dict<span class="token punctuation">(</span>road_Fake<span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">)</span>
to_dict<span class="token punctuation">(</span>road_Real<span class="token punctuation">,</span>dicts_Real<span class="token punctuation">)</span>

<span class="token comment">### Ëß£ÊûêË∞£Ë®ÄÂíåÁúüÊñ∞ÈóªÊï∞ÊçÆ</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">111</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    str_Fake<span class="token operator">=</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"authors"</span><span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"tittle"</span><span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">'url'</span><span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>str_Fake<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>str_Fake<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>str_Fake<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>removePunctuation<span class="token punctuation">(</span>str_Fake<span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>changePunctuation<span class="token punctuation">(</span>str_Fake<span class="token punctuation">)</span>
    all_rumor_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>rumor_label <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> str_Fake<span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>
    rumor_num <span class="token operator">+=</span> <span class="token number">1</span>
    str_Real<span class="token operator">=</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"authors"</span><span class="token punctuation">,</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"tittle"</span><span class="token punctuation">,</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">'url'</span><span class="token punctuation">,</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>str_Real<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>str_Real<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>str_Real<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>removePunctuation<span class="token punctuation">(</span>str_Real<span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>changePunctuation<span class="token punctuation">(</span>str_Real<span class="token punctuation">)</span>
    all_non_rumor_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>non_rumor_label <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> str_Real<span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>
    non_rumor_num <span class="token operator">+=</span> <span class="token number">1</span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Ë∞£Ë®ÄÊï∞ÊçÆÊÄªÈáè‰∏∫Ôºö"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>rumor_num<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ÁúüÊñ∞ÈóªÊï∞ÊçÆÊÄªÈáè‰∏∫Ôºö"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>non_rumor_num<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### ÂÖ®ÈÉ®Êï∞ÊçÆËøõË°å‰π±Â∫èÂêéÂÜôÂÖ•all_data.txt</span>

data_list_path <span class="token operator">=</span> <span class="token string">"C:\\Users\\34538\Desktop\EÈ¢òÈôÑ‰ª∂\ÈôÑ‰ª∂1.ËÆ≠ÁªÉÊï∞ÊçÆ\\all_data\\"</span>
all_data_path <span class="token operator">=</span> data_list_path <span class="token operator">+</span> <span class="token string">"all_data.txt"</span>

all_data_list <span class="token operator">=</span> all_rumor_list <span class="token operator">+</span> all_non_rumor_list

<span class="token comment">### ÊåâÈöèÊú∫Êï∞ÈöèÊú∫Êâì‰π±Êï∞ÊçÆ</span>
random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>all_data_list<span class="token punctuation">)</span>

<span class="token comment">### ÁîüÊàêall_data.txt‰πãÂâçÔºåÈ¶ñÂÖàÂ∞ÜÂÖ∂Ê∏ÖÁ©∫</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> all_data_list<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token comment">### ÁîüÊàêÊï∞ÊçÆÂ≠óÂÖ∏</span>
<span class="token keyword">def</span> <span class="token function">create_dict</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> dict_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dict_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># ËØªÂèñÂÖ®ÈÉ®Êï∞ÊçÆ</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># ÊääÊï∞ÊçÆÁîüÊàê‰∏Ä‰∏™ÂÖÉÁªÑ</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
        content <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>
        removePunctuation<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
        <span class="token keyword">for</span> s <span class="token keyword">in</span> content<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            dict_set<span class="token punctuation">.</span>add<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
    <span class="token comment"># ÊääÂÖÉÁªÑËΩ¨Êç¢ÊàêÂ≠óÂÖ∏Ôºå‰∏Ä‰∏™ÂçïËØçÂØπÂ∫î‰∏Ä‰∏™Êï∞Â≠ó</span>
    dict_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    i <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> s <span class="token keyword">in</span> dict_set<span class="token punctuation">:</span>
        dict_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>s<span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        i <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token comment"># Ê∑ªÂä†Êú™Áü•Â≠óÁ¨¶</span>
    dict_txt <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>dict_list<span class="token punctuation">)</span>
    end_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"&lt;unk&gt;"</span><span class="token punctuation">:</span> i<span class="token punctuation">}</span>
    dict_txt<span class="token punctuation">.</span>update<span class="token punctuation">(</span>end_dict<span class="token punctuation">)</span>
    <span class="token comment"># ÊääËøô‰∫õÂ≠óÂÖ∏‰øùÂ≠òÂà∞Êú¨Âú∞‰∏≠</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Êï∞ÊçÆÂ≠óÂÖ∏ÁîüÊàêÂÆåÊàêÔºÅ"</span><span class="token punctuation">)</span>


<span class="token comment">### Ëé∑ÂèñÂ≠óÂÖ∏ÁöÑÈïøÂ∫¶</span>
<span class="token keyword">def</span> <span class="token function">get_dict_len</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        line <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment">### ÂàõÂª∫Â∫èÂàóÂåñË°®Á§∫ÁöÑÊï∞ÊçÆ,</span>
<span class="token keyword">def</span> <span class="token function">create_data_list</span><span class="token punctuation">(</span>data_list_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Âú®ÁîüÊàêÊï∞ÊçÆ‰πãÂâçÔºåÈ¶ñÂÖàÂ∞Ütrain_list.txtÊ∏ÖÁ©∫</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'train_list.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_train<span class="token punctuation">:</span>
        f_train<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        f_train<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'dict.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        dict_txt <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'all_data.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    i <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'train_list.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_train<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">continue</span>
            words <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span>
            label <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            removePunctuation<span class="token punctuation">(</span>words<span class="token punctuation">)</span>
            labs <span class="token operator">=</span> <span class="token string">""</span>
            <span class="token keyword">for</span> s <span class="token keyword">in</span> words<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                lab <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>dict_txt <span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">)</span>
                labs <span class="token operator">=</span> labs <span class="token operator">+</span> lab <span class="token operator">+</span> <span class="token string">','</span>
            labs <span class="token operator">=</span> labs <span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
            labs <span class="token operator">=</span> labs <span class="token operator">+</span> <span class="token string">'\t'</span> <span class="token operator">+</span> label <span class="token operator">+</span> <span class="token string">'\n'</span>
            f_train<span class="token punctuation">.</span>write<span class="token punctuation">(</span>labs<span class="token punctuation">)</span>
            i <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Êï∞ÊçÆÂàóË°®ÁîüÊàêÂÆåÊàêÔºÅ"</span><span class="token punctuation">)</span>

<span class="token comment">### dict_path‰∏∫Êï∞ÊçÆÂ≠óÂÖ∏Â≠òÊîæË∑ØÂæÑ</span>
dict_path <span class="token operator">=</span> data_list_path <span class="token operator">+</span> <span class="token string">"dict.txt"</span>

<span class="token comment">### ÂàõÂª∫Êï∞ÊçÆÂ≠óÂÖ∏ÔºåÂ≠òÊîæ‰ΩçÁΩÆÔºödict.txt„ÄÇÂú®ÁîüÊàê‰πãÂâçÂÖàÊ∏ÖÁ©∫dict.txt</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span>
create_dict<span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> dict_path<span class="token punctuation">)</span>

<span class="token comment">### ÂàõÂª∫Êï∞ÊçÆÂàóË°®ÔºåÂ≠òÊîæ‰ΩçÁΩÆÔºötrain_list.txt</span>
create_data_list<span class="token punctuation">(</span>data_list_path<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">data_mapper</span><span class="token punctuation">(</span>sample<span class="token punctuation">)</span><span class="token punctuation">:</span>
    data<span class="token punctuation">,</span> label <span class="token operator">=</span> sample
    new_data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> i<span class="token punctuation">.</span>isdigit<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">continue</span>
        new_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> new_data<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span>

<span class="token comment">### ÂÆö‰πâÊï∞ÊçÆËØªÂèñÂô®</span>
<span class="token keyword">def</span> <span class="token function">data_reader</span><span class="token punctuation">(</span>data_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">reader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
                <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>
                data<span class="token punctuation">,</span> label <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
                <span class="token keyword">yield</span> data<span class="token punctuation">,</span> label
    <span class="token keyword">return</span> paddle<span class="token punctuation">.</span>reader<span class="token punctuation">.</span>xmap_readers<span class="token punctuation">(</span>data_mapper<span class="token punctuation">,</span> reader<span class="token punctuation">,</span> cpu_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>

<span class="token comment">### Ëé∑ÂèñËÆ≠ÁªÉÊï∞ÊçÆËØªÂèñÂô®</span>
BATCH_SIZE <span class="token operator">=</span> <span class="token number">16</span> <span class="token comment">#Áª¥Â∫¶ÂèÇÊï∞ËÆæÁΩÆ</span>

train_list_path <span class="token operator">=</span> data_list_path<span class="token operator">+</span><span class="token string">'train_list.txt'</span>

train_reader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>
		reader<span class="token operator">=</span>data_reader<span class="token punctuation">(</span>train_list_path<span class="token punctuation">)</span><span class="token punctuation">,</span>
		batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">)</span>

<span class="token comment">### ÂÆö‰πâÈïøÁü≠ÊúüËÆ∞ÂøÜÁΩëÁªú</span>

<span class="token keyword">def</span> <span class="token function">lstm_net</span><span class="token punctuation">(</span>ipt<span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>

 <span class="token comment">#‰ª•Êï∞ÊçÆÁöÑIDs‰Ωú‰∏∫ËæìÂÖ•</span>

emb <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>ipt<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">[</span>input_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span> is_sparse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># Á¨¨‰∏Ä‰∏™ÂÖ®ËøûÊé•Â±Ç</span>

fc1 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>emb<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>

<span class="token comment">#ËøõË°å‰∏Ä‰∏™ÈïøÁü≠ÊúüËÆ∞ÂøÜÊìç‰Ωú</span>

lstm1<span class="token punctuation">,</span> _ <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dynamic_lstm<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>fc1<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>
<span class="token comment">#Á¨¨‰∏Ä‰∏™ÊúÄÂ§ßÂ∫èÂàóÊ±†Êìç‰Ωú</span>
fc2 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>sequence_pool<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>fc1<span class="token punctuation">,</span> pool_type<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">)</span>
<span class="token comment">#Á¨¨‰∫å‰∏™ÊúÄÂ§ßÂ∫èÂàóÊ±†Êìç‰Ωú</span>
lstm2 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>sequence_pool<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>lstm1<span class="token punctuation">,</span> pool_type<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">)</span>
<span class="token comment">#‰ª•softmax‰Ωú‰∏∫ÂÖ®ËøûÊé•ÁöÑËæìÂá∫Â±ÇÔºåÂ§ßÂ∞è‰∏∫2,‰πüÂ∞±ÊòØÊ≠£Ë¥üÈù¢</span>
out <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token punctuation">[</span>fc2<span class="token punctuation">,</span> lstm2<span class="token punctuation">]</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token keyword">return</span> out

<span class="token comment">### ÂÆö‰πâËæìÂÖ•Êï∞ÊçÆÔºå lod_level‰∏ç‰∏∫0ÊåáÂÆöËæìÂÖ•Êï∞ÊçÆ‰∏∫Â∫èÂàóÊï∞ÊçÆ</span>
words <span class="token operator">=</span> fluid<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'words'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int64'</span><span class="token punctuation">,</span> lod_level<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
label <span class="token operator">=</span> fluid<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'label'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int64'</span><span class="token punctuation">)</span>

<span class="token comment">### Ëé∑ÂèñÊï∞ÊçÆÂ≠óÂÖ∏ÈïøÂ∫¶</span>
dict_dim <span class="token operator">=</span> get_dict_len<span class="token punctuation">(</span>dict_path<span class="token punctuation">)</span>
<span class="token comment">### Ëé∑ÂèñÂàÜÁ±ªÂô®</span>
model <span class="token operator">=</span> lstm_net<span class="token punctuation">(</span>words<span class="token punctuation">,</span> dict_dim<span class="token punctuation">)</span>

<span class="token comment">### Ëé∑ÂèñÊçüÂ§±ÂáΩÊï∞ÂíåÂáÜÁ°ÆÁéá</span>
cost <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>model<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span>
avg_cost <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
acc <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>model<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span>

<span class="token comment">### Ëé∑ÂèñÈ¢ÑÊµãÁ®ãÂ∫è</span>
test_program <span class="token operator">=</span> fluid<span class="token punctuation">.</span>default_main_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clone<span class="token punctuation">(</span>for_test<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">### ÂÆö‰πâ‰ºòÂåñÊñπÊ≥ï</span>
optimizer <span class="token operator">=</span> fluid<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>AdagradOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
opt <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>avg_cost<span class="token punctuation">)</span>


use_cuda <span class="token operator">=</span> <span class="token boolean">False</span>
place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CUDAPlace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">if</span> use_cuda <span class="token keyword">else</span> fluid<span class="token punctuation">.</span>CPUPlace<span class="token punctuation">(</span><span class="token punctuation">)</span>
exe <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Executor<span class="token punctuation">(</span>place<span class="token punctuation">)</span>

<span class="token comment">### ËøõË°åÂèÇÊï∞ÂàùÂßãÂåñ</span>
exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>default_startup_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### ÂÆö‰πâÊï∞ÊçÆÊò†Â∞ÑÂô®</span>
feeder <span class="token operator">=</span> fluid<span class="token punctuation">.</span>DataFeeder<span class="token punctuation">(</span>place<span class="token operator">=</span>place<span class="token punctuation">,</span> feed_list<span class="token operator">=</span><span class="token punctuation">[</span>words<span class="token punctuation">,</span> label<span class="token punctuation">]</span><span class="token punctuation">)</span>

all_train_iter<span class="token operator">=</span><span class="token number">0</span>
all_train_iters<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
all_train_costs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
all_train_accs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">draw_process</span><span class="token punctuation">(</span>title<span class="token punctuation">,</span>iters<span class="token punctuation">,</span>costs<span class="token punctuation">,</span>accs<span class="token punctuation">,</span>label_cost<span class="token punctuation">,</span>lable_acc<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>title<span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"iter"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"cost/acc"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>iters<span class="token punctuation">,</span> costs<span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span>label<span class="token operator">=</span>label_cost<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>iters<span class="token punctuation">,</span> accs<span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'green'</span><span class="token punctuation">,</span>label<span class="token operator">=</span>lable_acc<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


EPOCH_NUM <span class="token operator">=</span> <span class="token number">10</span>  <span class="token comment"># ËÆ≠ÁªÉËΩÆÊï∞</span>
model_save_dir <span class="token operator">=</span> <span class="token string">'C:\\Users\\34538\Desktop\EÈ¢òÈôÑ‰ª∂\\'</span>  
 <span class="token comment"># Ê®°Âûã‰øùÂ≠òË∑ØÂæÑ</span>

<span class="token comment">### ÂºÄÂßãËÆ≠ÁªÉ</span>
<span class="token keyword">for</span> pass_id <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>EPOCH_NUM<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># ËøõË°åËÆ≠ÁªÉ</span>
    <span class="token keyword">for</span> batch_id<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_reader<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_cost<span class="token punctuation">,</span> train_acc <span class="token operator">=</span> exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>program<span class="token operator">=</span>fluid<span class="token punctuation">.</span>default_main_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        feed<span class="token operator">=</span>feeder<span class="token punctuation">.</span>feed<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        fetch_list<span class="token operator">=</span><span class="token punctuation">[</span>avg_cost<span class="token punctuation">,</span> acc<span class="token punctuation">]</span><span class="token punctuation">)</span>
        all_train_iter <span class="token operator">=</span> all_train_iter <span class="token operator">+</span> BATCH_SIZE
        all_train_iters<span class="token punctuation">.</span>append<span class="token punctuation">(</span>all_train_iter<span class="token punctuation">)</span>
        all_train_costs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_cost <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        all_train_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> batch_id <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Pass:%d, Batch:%d, Cost:%0.5f, Acc:%0.5f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>pass_id<span class="token punctuation">,</span> batch_id<span class="token punctuation">,</span> train_cost <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_acc <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### ‰øùÂ≠òÊ®°Âûã</span>
<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>model_save_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>model_save_dir<span class="token punctuation">)</span>
fluid<span class="token punctuation">.</span>io<span class="token punctuation">.</span>save_inference_model<span class="token punctuation">(</span>model_save_dir<span class="token punctuation">,</span>
                              feeded_var_names<span class="token operator">=</span><span class="token punctuation">[</span>words<span class="token punctuation">.</span>name<span class="token punctuation">]</span><span class="token punctuation">,</span>
                              target_vars<span class="token operator">=</span><span class="token punctuation">[</span>model<span class="token punctuation">]</span><span class="token punctuation">,</span>
                              executor<span class="token operator">=</span>exe<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'ËÆ≠ÁªÉÊ®°Âûã‰øùÂ≠òÂÆåÊàêÔºÅ'</span><span class="token punctuation">)</span>

draw_process<span class="token punctuation">(</span><span class="token string">"train"</span><span class="token punctuation">,</span> all_train_iters<span class="token punctuation">,</span> all_train_costs<span class="token punctuation">,</span> all_train_accs<span class="token punctuation">,</span> <span class="token string">"trainning cost"</span><span class="token punctuation">,</span> <span class="token string">"trainning acc"</span><span class="token punctuation">)</span>

test_data<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>
road_test<span class="token operator">=</span><span class="token string">"test"</span>    <span class="token comment">#ÊµãËØïÊï∞ÊçÆÊñá‰ª∂Â§πË∑ØÂæÑ</span>

<span class="token comment">#ÂÆö‰πâjsonËΩ¨Â≠óÂÖ∏ÂáΩÊï∞</span>
<span class="token keyword">def</span> <span class="token function">to_test_dict</span><span class="token punctuation">(</span>road<span class="token punctuation">,</span>dicts<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        filename<span class="token operator">=</span><span class="token string">r"C:\\Users\34538\Desktop\EÈ¢òÈôÑ‰ª∂\ÈôÑ‰ª∂2.ÊµãËØïÊï∞ÊçÆ\\"</span><span class="token operator">+</span>road<span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">".json"</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            txt<span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
            dicts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>txt

to_test_dict<span class="token punctuation">(</span>road_test<span class="token punctuation">,</span>test_data<span class="token punctuation">)</span>

test_sum<span class="token operator">=</span><span class="token number">0</span>
test_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    str_test <span class="token operator">=</span> test_data <span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> judge<span class="token punctuation">(</span><span class="token string">"authors"</span><span class="token punctuation">,</span> test_data <span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> judge<span class="token punctuation">(</span><span class="token string">"tittle"</span><span class="token punctuation">,</span> test_data <span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> str_test<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> str_test<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> str_test<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> removePunctuation<span class="token punctuation">(</span>str_test<span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> changePunctuation<span class="token punctuation">(</span>str_test<span class="token punctuation">)</span>
    test_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>str_test<span class="token punctuation">)</span>
    test_sum <span class="token operator">+=</span> <span class="token number">1</span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ÊµãËØïÊï∞ÊçÆÊÄªÈáè‰∏∫Ôºö"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_sum<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment">### ÂàõÂª∫ÊâßË°åÂô®</span>
place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CPUPlace<span class="token punctuation">(</span><span class="token punctuation">)</span>
infer_exe <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Executor<span class="token punctuation">(</span>place<span class="token punctuation">)</span>
infer_exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>default_startup_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

save_path <span class="token operator">=</span> <span class="token string">'C:\\Users\\34538\Desktop\EÈ¢òÈôÑ‰ª∂\\'</span>

<span class="token punctuation">[</span>infer_program<span class="token punctuation">,</span> feeded_var_names<span class="token punctuation">,</span> target_var<span class="token punctuation">]</span> <span class="token operator">=</span> fluid<span class="token punctuation">.</span>io<span class="token punctuation">.</span>load_inference_model<span class="token punctuation">(</span>dirname<span class="token operator">=</span>save_path<span class="token punctuation">,</span> executor<span class="token operator">=</span>infer_exe<span class="token punctuation">)</span>


<span class="token comment">### Ëé∑ÂèñÊï∞ÊçÆ</span>
<span class="token keyword">def</span> <span class="token function">get_data</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># ËØªÂèñÊï∞ÊçÆÂ≠óÂÖ∏</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'C:\\Users\\34538\Desktop\EÈ¢òÈôÑ‰ª∂\ÈôÑ‰ª∂1.ËÆ≠ÁªÉÊï∞ÊçÆ\\all_data\dict.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        dict_txt <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    dict_txt <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">)</span>
    <span class="token comment"># ÊääÂ≠óÁ¨¶‰∏≤Êï∞ÊçÆËΩ¨Êç¢ÊàêÂàóË°®Êï∞ÊçÆ</span>
    keys <span class="token operator">=</span> dict_txt<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> s <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>
        <span class="token comment"># Âà§Êñ≠ÊòØÂê¶Â≠òÂú®Êú™Áü•Â≠óÁ¨¶</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> s <span class="token keyword">in</span> keys<span class="token punctuation">:</span>
            s <span class="token operator">=</span> <span class="token string">'&lt;unk&gt;'</span>
        data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">(</span>dict_txt<span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> data

data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token comment">### Ëé∑ÂèñÂÖ®ÈÉ®ÊµãËØïÊï∞ÊçÆ</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>get_data<span class="token punctuation">(</span>removePunctuation<span class="token punctuation">(</span>test_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### Ëé∑ÂèñÊØèÂè•ËØùÁöÑÂçïËØçÊï∞Èáè</span>
base_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> data<span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment">### ÁîüÊàêÈ¢ÑÊµãÊï∞ÊçÆ</span>

tensor_words <span class="token operator">=</span> fluid<span class="token punctuation">.</span>create_lod_tensor<span class="token punctuation">(</span>data<span class="token punctuation">,</span> base_shape<span class="token punctuation">,</span> place<span class="token punctuation">)</span>

<span class="token comment">### ÊâßË°åÈ¢ÑÊµã</span>

result <span class="token operator">=</span> exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>program<span class="token operator">=</span>infer_program<span class="token punctuation">,</span>feed<span class="token operator">=</span><span class="token punctuation">{</span>feeded_var_names<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tensor_words<span class="token punctuation">}</span><span class="token punctuation">,</span>fetch_list<span class="token operator">=</span>target_var<span class="token punctuation">)</span>

names <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token string">'Ë∞£Ë®Ä'</span><span class="token punctuation">,</span> <span class="token string">'ÁúüÊñ∞Èóª'</span><span class="token punctuation">]</span>

<span class="token comment">### ËøõË°åÈ¢ÑÊµãÂπ∂ËØÑ‰ª∑È¢ÑÊµãÁªìÊûú</span>


<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    lab <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'È¢ÑÊµãÁªìÊûúÊ†áÁ≠æ‰∏∫Ôºö%dÔºå ÂàÜÁ±ª‰∏∫Ôºö%sÔºå Ê¶ÇÁéá‰∏∫Ôºö%f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>lab<span class="token punctuation">,</span> names<span class="token punctuation">[</span>lab<span class="token punctuation">]</span><span class="token punctuation">,</span> result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>lab<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

        </div>

    </div>

    

    

    

    
  <div class="article-copyright hairline">
    <p>
      Êú¨‰ΩúÂìÅÈááÁî®  <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">Áü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Á¶ÅÊ≠¢ÊºîÁªé 4.0 ÂõΩÈôÖËÆ∏ÂèØÂçèËÆÆ (CC BY-NC-ND 4.0)</a> ËøõË°åËÆ∏ÂèØ„ÄÇ
    </p>
  </div>
  

    

    
<nav class="article-nav">
  
    <a href="/2022/xsslabs/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-caption">‰∏ã‰∏ÄÁØá</div>
      <div class="article-nav-title">
        
          Èù∂Âú∫Êó•ËÆ∞-Ë∑®Á´ôËØ∑Ê±ÇXSSlabs
        
      </div>
    </a>
  
  
    <a href="/2022/gxds/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-caption">‰∏ä‰∏ÄÁØá</div>
      <div class="article-nav-title">Êï∞ÊçÆÂ∫ì-ÂÖ≥Á≥ª‰ª£Êï∞ËØ≠Ë®Ä</div>
    </a>
  
</nav>


    <section class="share">
        <div class="share-title">ÂàÜ‰∫´</div>
        <a class="share-item" target="_blank"
            href="https://twitter.com/share?text=Êï∞Â≠¶Âª∫Ê®°-RNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªú - Kmoon&url=https%3A%2F%2Fwww.kmoon.fun%2F2022%2Frnn%2F">
            <ion-icon name="logo-twitter"></ion-icon>
        </a>
        <a class="share-item" target="_blank"
            href="https://www.facebook.com/sharer.php?title=Êï∞Â≠¶Âª∫Ê®°-RNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªú - Kmoon&u=https%3A%2F%2Fwww.kmoon.fun%2F2022%2Frnn%2F">
            <ion-icon name="logo-facebook"></ion-icon>
        </a>
        <!-- <a class="share-item" target="_blank"
            href="https://service.weibo.com/share/share.php?title=Êï∞Â≠¶Âª∫Ê®°-RNNÂç∑ÁßØÁ•ûÁªèÁΩëÁªú - Kmoon&url=https://www.kmoon.fun/2022/rnn/&pic=">
            <div class="n-icon n-icon-weibo"></div>
        </a> -->
    </section>

</article>










<section class="comments">
    <div id="valine-container"></div>
</section>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>







<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</div>
                </section>
            </section>

            
            <aside class="sidebar sidebar-search-fix">
                

    <div class="search">
    <div class="has-icon-right">
        <input type="text" class="form-input" id="search" placeholder="SEARCH" autocomplete="off">
        <div class="form-icon">
            <ion-icon name="search"></ion-icon>
        </div>
    </div>
    <div class="search-result" id="search-ps"></div>
</div>


<div class="widget" id="widget">
    
      
  <div class="widget-wrap">
    <div class="widget-inner">
      <div class="toc post-toc-html"></div>
    </div>
  </div>

    
      
  <div class="widget-wrap widget-cate">
    <div class="widget-title"><span>Categories</span></div>
    <div class="widget-inner">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/SRC/">SRC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Sec/">Sec</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/SecTools/">SecTools</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/WebSec/">WebSec</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Whut/">Whut</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Windows/">Windows</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/XiaoHu-s-Daily/">XiaoHu's Daily</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/action/">action</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/markdwon/">markdwon</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E6%9C%AD%E8%AE%B0/">Â≠¶‰π†Êú≠ËÆ∞</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">ÂÆûÈ™åÊä•Âëä</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%87%92%E4%BA%BA%E5%BF%85%E5%A4%87/">Êáí‰∫∫ÂøÖÂ§á</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">Êï∞ÊçÆÁªìÊûÑ</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9D%B6%E5%9C%BA%E6%97%A5%E8%AE%B0/">Èù∂Âú∫Êó•ËÆ∞</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%A1%B9%E7%9B%AE%E8%AE%A1%E5%88%92/">È°πÁõÆËÆ°Âàí</a></li></ul>
    </div>
  </div>


    
      
  <div class="widget-wrap widget-tags">
    <div class="widget-title"><span>Tags</span></div>
    <div class="widget-inner">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/" rel="tag">C</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/" rel="tag">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SRC/" rel="tag">SRC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sec/" rel="tag">Sec</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tools/" rel="tag">Tools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Whut/" rel="tag">Whut</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Windows/" rel="tag">Windows</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XSS/" rel="tag">XSS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/daily/" rel="tag">daily</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hacker/" rel="tag">hacker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdwon/" rel="tag">markdwon</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/me/" rel="tag">me</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/upload/" rel="tag">upload</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%95%E7%89%87%E6%9C%BA/" rel="tag">ÂçïÁâáÊú∫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" rel="tag">Êï∞Â≠¶Âª∫Ê®°</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">Êï∞ÊçÆÂ∫ì</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">Êï∞ÊçÆÁªìÊûÑ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%BD%91/" rel="tag">ËÆ°ÁΩë</a></li></ul>
    </div>
  </div>


    
      
  <div class="widget-wrap widget-recent-posts">
    <div class="widget-title"><span>Recent Posts</span></div>
    <div class="widget-inner">
      <ul>
        
          <li>
            <a href="/2022/action/">ÂºÄÈó®ËßÅÂ±±-Ê¨¢ËøéÊù•Âà∞KmoonÁöÑÂ∞è‰∏ñÁïå</a>
          </li>
        
          <li>
            <a href="/2022/wut-c-cheng-xu-she-ji-shi-yan-bao-gao/">WUT-C++Á®ãÂ∫èËÆæËÆ°ÂÆûÈ™åÊä•Âëä</a>
          </li>
        
          <li>
            <a href="/2022/project1/">È°πÁõÆËÆ°Âàí-[Êé®Êé®]:Â∞èËØ¥Êõ¥Êñ∞Â∞±ÈÄöÁü•(ÊµãËØï)</a>
          </li>
        
          <li>
            <a href="/2022/jwtk/">WUT-ËÆ°ÁÆóÊú∫ÁΩëÁªúÈ¢òÂ∫ìÈöæÁÇπÊµÖËß£</a>
          </li>
        
          <li>
            <a href="/2022/software/">WUT-ÂçïÁâáÊú∫EDAËΩØ‰ª∂Â∑•ÂÖ∑‰∏ãËΩΩ</a>
          </li>
        
      </ul>
    </div>
  </div>

    
      
  <div class="widget-wrap widget-archive">
    <div class="widget-title"><span>Archive</span></div>
    <div class="widget-inner">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a></li></ul>
    </div>
  </div>


    
</div>

<div id="backtop"><i class="icon icon-arrow-up"></i></div>
            </aside>
            
        </div>
    </div>

    <footer class="footer">
    <div class="footer-wave">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1440 320"><path fill="#3c4859" fill-opacity="1" d="M0,160L60,181.3C120,203,240,245,360,240C480,235,600,181,720,186.7C840,192,960,256,1080,261.3C1200,267,1320,213,1380,186.7L1440,160L1440,320L1380,320C1320,320,1200,320,1080,320C960,320,840,320,720,320C600,320,480,320,360,320C240,320,120,320,60,320L0,320Z"></path></svg>
    </div>

    <!-- Please do not remove this -->
    <!-- ÂºÄÊ∫ê‰∏çÊòìÔºåËØ∑ÂãøÂà†Èô§ -->
    <div class="footer-wrap">
        <div class="footer-inner"> 
            Kmoon &copy; 2022<br>
            Powered By Hexo ¬∑ Theme By <a href="https://linhong.me/" target="_blank">Aomori</a> ¬∑ <a href="https://github.com/lh1me/hexo-theme-aomori" target="_blank">Github</a>
        </div>
    </div>

</footer>

<script type="module" src="https://unpkg.com/ionicons@6.0.2/dist/ionicons/ionicons.esm.js"></script>






<script src="/dist/build.js?1654266144177.js"></script>


<script src="/dist/custom.js?1654266144177.js"></script>



<!-- ÁôæÂ∫¶ÈìæÊé•Êèê‰∫§ -->
<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>



<!-- Google Analytics-->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXX-X"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-XXXXX-X');
</script>









<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":220,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>
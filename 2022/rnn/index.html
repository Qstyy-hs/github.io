<!DOCTYPE html>
<html lang=zh-CN>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:description" content="">
    <meta property="og:type" content="website">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        数学建模-RNN卷积神经网络 - Kmoon
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

    
<link rel="stylesheet" href="/css/gitment.css">

    <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
    <link href="//at.alicdn.com/t/font_620856_28hi1hpxx24.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 6.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>
<script type="text/javascript" src="https://cdn.lanluo.cn/js/canvas-nest.min.js"></script>
<body>
    <script type="text/javascript" src="https://cdn.lanluo.cn/js/canvas-nest.min.js"></script>
<script>
    var _hmt = _hmt || [];
    (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?cb7a49e4f6a740b15e6fd25de2803712";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>
<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 千山同一月 万物皆清明 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar radius">
            <img src="/img/avatar.png" />
        </div>
        <div class="name">
            <i>Kmoon</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-bg" id="search-bg"></div>
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 千山同一月 万物皆清明 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        <div class="post-container">
    <div class="post-title">
        数学建模-RNN卷积神经网络
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2022-08-11 15:46:47</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#数学建模" title="数学建模">数学建模</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content no-indent">
        <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">### 导入必要的库</span>
<span class="token keyword">import</span> json
<span class="token keyword">import</span> os
<span class="token keyword">import</span> random
<span class="token keyword">import</span> re
<span class="token keyword">from</span> multiprocessing <span class="token keyword">import</span> cpu_count
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> paddle
<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>fluid <span class="token keyword">as</span> fluid
paddle<span class="token punctuation">.</span>enable_static<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment">### 去除字符串的标点符号</span>
r<span class="token operator">=</span><span class="token string">'[’!"\'()+,-./:;&lt;=&gt;?@[\\]`{|}~\n。！，]+'</span>
<span class="token keyword">def</span> <span class="token function">removePunctuation</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    line<span class="token operator">=</span>re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">,</span>text<span class="token punctuation">)</span>
    <span class="token keyword">return</span> line

<span class="token comment">### 提取特殊符号</span>
s<span class="token operator">=</span><span class="token string">'…@#^&amp;*'</span>
<span class="token keyword">def</span> <span class="token function">changePunctuation</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> s<span class="token punctuation">:</span>
        <span class="token keyword">if</span> i <span class="token keyword">in</span> text<span class="token punctuation">:</span>
            text<span class="token operator">=</span>text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>s<span class="token punctuation">,</span><span class="token string">' '</span><span class="token operator">+</span>s<span class="token operator">+</span><span class="token string">' '</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> text
<span class="token comment">### 数据字典索引存在判断</span>
<span class="token keyword">def</span> <span class="token function">judge</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">,</span><span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">str</span> <span class="token keyword">in</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">str</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">""</span>
    
<span class="token comment">### 分别统计谣言数据与真新闻数据的总数</span>
rumor_num <span class="token operator">=</span> <span class="token number">0</span>
non_rumor_num <span class="token operator">=</span> <span class="token number">0</span>

all_rumor_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
all_non_rumor_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment">### 谣言标签为0，真新闻标签为1</span>
rumor_label <span class="token operator">=</span> <span class="token string">"0"</span>
non_rumor_label <span class="token operator">=</span> <span class="token string">"1"</span>

dicts_Fake<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token comment">#声明谣言字典</span>
dicts_Real<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token comment">#声明真新闻字典</span>
road_Fake<span class="token operator">=</span><span class="token string">"谣言\PolitiFact_Fake_"</span>     <span class="token comment">#谣言文件夹路径</span>
road_Real<span class="token operator">=</span><span class="token string">"真新闻\PolitiFact_Real_"</span>    <span class="token comment">#真新闻文件夹路径</span>

<span class="token comment">### 定义json转字典函数</span>
<span class="token keyword">def</span> <span class="token function">to_dict</span><span class="token punctuation">(</span>road<span class="token punctuation">,</span>dicts<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">111</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        filename<span class="token operator">=</span><span class="token string">r"C:\\Users\34538\Desktop\E题附件\附件1.训练数据\\"</span><span class="token operator">+</span>road<span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"-Webpage.json"</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            txt<span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
            dicts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>txt

<span class="token comment">### 构建谣言和真新闻字典</span>
to_dict<span class="token punctuation">(</span>road_Fake<span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">)</span>
to_dict<span class="token punctuation">(</span>road_Real<span class="token punctuation">,</span>dicts_Real<span class="token punctuation">)</span>

<span class="token comment">### 解析谣言和真新闻数据</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">111</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    str_Fake<span class="token operator">=</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"authors"</span><span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"tittle"</span><span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">'url'</span><span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>str_Fake<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>str_Fake<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>str_Fake<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>removePunctuation<span class="token punctuation">(</span>str_Fake<span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>changePunctuation<span class="token punctuation">(</span>str_Fake<span class="token punctuation">)</span>
    all_rumor_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>rumor_label <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> str_Fake<span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>
    rumor_num <span class="token operator">+=</span> <span class="token number">1</span>
    str_Real<span class="token operator">=</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"authors"</span><span class="token punctuation">,</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"tittle"</span><span class="token punctuation">,</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">'url'</span><span class="token punctuation">,</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>str_Real<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>str_Real<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>str_Real<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>removePunctuation<span class="token punctuation">(</span>str_Real<span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>changePunctuation<span class="token punctuation">(</span>str_Real<span class="token punctuation">)</span>
    all_non_rumor_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>non_rumor_label <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> str_Real<span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>
    non_rumor_num <span class="token operator">+=</span> <span class="token number">1</span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"谣言数据总量为："</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>rumor_num<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"真新闻数据总量为："</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>non_rumor_num<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### 全部数据进行乱序后写入all_data.txt</span>

data_list_path <span class="token operator">=</span> <span class="token string">"C:\\Users\\34538\Desktop\E题附件\附件1.训练数据\\all_data\\"</span>
all_data_path <span class="token operator">=</span> data_list_path <span class="token operator">+</span> <span class="token string">"all_data.txt"</span>

all_data_list <span class="token operator">=</span> all_rumor_list <span class="token operator">+</span> all_non_rumor_list

<span class="token comment">### 按随机数随机打乱数据</span>
random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>all_data_list<span class="token punctuation">)</span>

<span class="token comment">### 生成all_data.txt之前，首先将其清空</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> all_data_list<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token comment">### 生成数据字典</span>
<span class="token keyword">def</span> <span class="token function">create_dict</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> dict_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dict_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 读取全部数据</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 把数据生成一个元组</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
        content <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>
        removePunctuation<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
        <span class="token keyword">for</span> s <span class="token keyword">in</span> content<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            dict_set<span class="token punctuation">.</span>add<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
    <span class="token comment"># 把元组转换成字典，一个单词对应一个数字</span>
    dict_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    i <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> s <span class="token keyword">in</span> dict_set<span class="token punctuation">:</span>
        dict_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>s<span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        i <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token comment"># 添加未知字符</span>
    dict_txt <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>dict_list<span class="token punctuation">)</span>
    end_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"&lt;unk&gt;"</span><span class="token punctuation">:</span> i<span class="token punctuation">}</span>
    dict_txt<span class="token punctuation">.</span>update<span class="token punctuation">(</span>end_dict<span class="token punctuation">)</span>
    <span class="token comment"># 把这些字典保存到本地中</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"数据字典生成完成！"</span><span class="token punctuation">)</span>


<span class="token comment">### 获取字典的长度</span>
<span class="token keyword">def</span> <span class="token function">get_dict_len</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        line <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment">### 创建序列化表示的数据,</span>
<span class="token keyword">def</span> <span class="token function">create_data_list</span><span class="token punctuation">(</span>data_list_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 在生成数据之前，首先将train_list.txt清空</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'train_list.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_train<span class="token punctuation">:</span>
        f_train<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        f_train<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'dict.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        dict_txt <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'all_data.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    i <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'train_list.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_train<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">continue</span>
            words <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span>
            label <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            removePunctuation<span class="token punctuation">(</span>words<span class="token punctuation">)</span>
            labs <span class="token operator">=</span> <span class="token string">""</span>
            <span class="token keyword">for</span> s <span class="token keyword">in</span> words<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                lab <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>dict_txt <span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">)</span>
                labs <span class="token operator">=</span> labs <span class="token operator">+</span> lab <span class="token operator">+</span> <span class="token string">','</span>
            labs <span class="token operator">=</span> labs <span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
            labs <span class="token operator">=</span> labs <span class="token operator">+</span> <span class="token string">'\t'</span> <span class="token operator">+</span> label <span class="token operator">+</span> <span class="token string">'\n'</span>
            f_train<span class="token punctuation">.</span>write<span class="token punctuation">(</span>labs<span class="token punctuation">)</span>
            i <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"数据列表生成完成！"</span><span class="token punctuation">)</span>

<span class="token comment">### dict_path为数据字典存放路径</span>
dict_path <span class="token operator">=</span> data_list_path <span class="token operator">+</span> <span class="token string">"dict.txt"</span>

<span class="token comment">### 创建数据字典，存放位置：dict.txt。在生成之前先清空dict.txt</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span>
create_dict<span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> dict_path<span class="token punctuation">)</span>

<span class="token comment">### 创建数据列表，存放位置：train_list.txt</span>
create_data_list<span class="token punctuation">(</span>data_list_path<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">data_mapper</span><span class="token punctuation">(</span>sample<span class="token punctuation">)</span><span class="token punctuation">:</span>
    data<span class="token punctuation">,</span> label <span class="token operator">=</span> sample
    new_data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> i<span class="token punctuation">.</span>isdigit<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">continue</span>
        new_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> new_data<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span>

<span class="token comment">### 定义数据读取器</span>
<span class="token keyword">def</span> <span class="token function">data_reader</span><span class="token punctuation">(</span>data_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">reader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
                <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>
                data<span class="token punctuation">,</span> label <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
                <span class="token keyword">yield</span> data<span class="token punctuation">,</span> label
    <span class="token keyword">return</span> paddle<span class="token punctuation">.</span>reader<span class="token punctuation">.</span>xmap_readers<span class="token punctuation">(</span>data_mapper<span class="token punctuation">,</span> reader<span class="token punctuation">,</span> cpu_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>

<span class="token comment">### 获取训练数据读取器</span>
BATCH_SIZE <span class="token operator">=</span> <span class="token number">16</span> <span class="token comment">#维度参数设置</span>

train_list_path <span class="token operator">=</span> data_list_path<span class="token operator">+</span><span class="token string">'train_list.txt'</span>

train_reader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>
		reader<span class="token operator">=</span>data_reader<span class="token punctuation">(</span>train_list_path<span class="token punctuation">)</span><span class="token punctuation">,</span>
		batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">)</span>

<span class="token comment">### 定义长短期记忆网络</span>

<span class="token keyword">def</span> <span class="token function">lstm_net</span><span class="token punctuation">(</span>ipt<span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>

 <span class="token comment">#以数据的IDs作为输入</span>

emb <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>ipt<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">[</span>input_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span> is_sparse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># 第一个全连接层</span>

fc1 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>emb<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>

<span class="token comment">#进行一个长短期记忆操作</span>

lstm1<span class="token punctuation">,</span> _ <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dynamic_lstm<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>fc1<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>
<span class="token comment">#第一个最大序列池操作</span>
fc2 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>sequence_pool<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>fc1<span class="token punctuation">,</span> pool_type<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">)</span>
<span class="token comment">#第二个最大序列池操作</span>
lstm2 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>sequence_pool<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>lstm1<span class="token punctuation">,</span> pool_type<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">)</span>
<span class="token comment">#以softmax作为全连接的输出层，大小为2,也就是正负面</span>
out <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token punctuation">[</span>fc2<span class="token punctuation">,</span> lstm2<span class="token punctuation">]</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token keyword">return</span> out

<span class="token comment">### 定义输入数据， lod_level不为0指定输入数据为序列数据</span>
words <span class="token operator">=</span> fluid<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'words'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int64'</span><span class="token punctuation">,</span> lod_level<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
label <span class="token operator">=</span> fluid<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'label'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int64'</span><span class="token punctuation">)</span>

<span class="token comment">### 获取数据字典长度</span>
dict_dim <span class="token operator">=</span> get_dict_len<span class="token punctuation">(</span>dict_path<span class="token punctuation">)</span>
<span class="token comment">### 获取分类器</span>
model <span class="token operator">=</span> lstm_net<span class="token punctuation">(</span>words<span class="token punctuation">,</span> dict_dim<span class="token punctuation">)</span>

<span class="token comment">### 获取损失函数和准确率</span>
cost <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>model<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span>
avg_cost <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
acc <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>model<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span>

<span class="token comment">### 获取预测程序</span>
test_program <span class="token operator">=</span> fluid<span class="token punctuation">.</span>default_main_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clone<span class="token punctuation">(</span>for_test<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">### 定义优化方法</span>
optimizer <span class="token operator">=</span> fluid<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>AdagradOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
opt <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>avg_cost<span class="token punctuation">)</span>


use_cuda <span class="token operator">=</span> <span class="token boolean">False</span>
place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CUDAPlace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">if</span> use_cuda <span class="token keyword">else</span> fluid<span class="token punctuation">.</span>CPUPlace<span class="token punctuation">(</span><span class="token punctuation">)</span>
exe <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Executor<span class="token punctuation">(</span>place<span class="token punctuation">)</span>

<span class="token comment">### 进行参数初始化</span>
exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>default_startup_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### 定义数据映射器</span>
feeder <span class="token operator">=</span> fluid<span class="token punctuation">.</span>DataFeeder<span class="token punctuation">(</span>place<span class="token operator">=</span>place<span class="token punctuation">,</span> feed_list<span class="token operator">=</span><span class="token punctuation">[</span>words<span class="token punctuation">,</span> label<span class="token punctuation">]</span><span class="token punctuation">)</span>

all_train_iter<span class="token operator">=</span><span class="token number">0</span>
all_train_iters<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
all_train_costs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
all_train_accs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">draw_process</span><span class="token punctuation">(</span>title<span class="token punctuation">,</span>iters<span class="token punctuation">,</span>costs<span class="token punctuation">,</span>accs<span class="token punctuation">,</span>label_cost<span class="token punctuation">,</span>lable_acc<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>title<span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"iter"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"cost/acc"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>iters<span class="token punctuation">,</span> costs<span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span>label<span class="token operator">=</span>label_cost<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>iters<span class="token punctuation">,</span> accs<span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'green'</span><span class="token punctuation">,</span>label<span class="token operator">=</span>lable_acc<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


EPOCH_NUM <span class="token operator">=</span> <span class="token number">10</span>  <span class="token comment"># 训练轮数</span>
model_save_dir <span class="token operator">=</span> <span class="token string">'C:\\Users\\34538\Desktop\E题附件\\'</span>  
 <span class="token comment"># 模型保存路径</span>

<span class="token comment">### 开始训练</span>
<span class="token keyword">for</span> pass_id <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>EPOCH_NUM<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 进行训练</span>
    <span class="token keyword">for</span> batch_id<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_reader<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_cost<span class="token punctuation">,</span> train_acc <span class="token operator">=</span> exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>program<span class="token operator">=</span>fluid<span class="token punctuation">.</span>default_main_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        feed<span class="token operator">=</span>feeder<span class="token punctuation">.</span>feed<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        fetch_list<span class="token operator">=</span><span class="token punctuation">[</span>avg_cost<span class="token punctuation">,</span> acc<span class="token punctuation">]</span><span class="token punctuation">)</span>
        all_train_iter <span class="token operator">=</span> all_train_iter <span class="token operator">+</span> BATCH_SIZE
        all_train_iters<span class="token punctuation">.</span>append<span class="token punctuation">(</span>all_train_iter<span class="token punctuation">)</span>
        all_train_costs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_cost <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        all_train_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> batch_id <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Pass:%d, Batch:%d, Cost:%0.5f, Acc:%0.5f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>pass_id<span class="token punctuation">,</span> batch_id<span class="token punctuation">,</span> train_cost <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_acc <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### 保存模型</span>
<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>model_save_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>model_save_dir<span class="token punctuation">)</span>
fluid<span class="token punctuation">.</span>io<span class="token punctuation">.</span>save_inference_model<span class="token punctuation">(</span>model_save_dir<span class="token punctuation">,</span>
                              feeded_var_names<span class="token operator">=</span><span class="token punctuation">[</span>words<span class="token punctuation">.</span>name<span class="token punctuation">]</span><span class="token punctuation">,</span>
                              target_vars<span class="token operator">=</span><span class="token punctuation">[</span>model<span class="token punctuation">]</span><span class="token punctuation">,</span>
                              executor<span class="token operator">=</span>exe<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练模型保存完成！'</span><span class="token punctuation">)</span>

draw_process<span class="token punctuation">(</span><span class="token string">"train"</span><span class="token punctuation">,</span> all_train_iters<span class="token punctuation">,</span> all_train_costs<span class="token punctuation">,</span> all_train_accs<span class="token punctuation">,</span> <span class="token string">"trainning cost"</span><span class="token punctuation">,</span> <span class="token string">"trainning acc"</span><span class="token punctuation">)</span>

test_data<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>
road_test<span class="token operator">=</span><span class="token string">"test"</span>    <span class="token comment">#测试数据文件夹路径</span>

<span class="token comment">#定义json转字典函数</span>
<span class="token keyword">def</span> <span class="token function">to_test_dict</span><span class="token punctuation">(</span>road<span class="token punctuation">,</span>dicts<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        filename<span class="token operator">=</span><span class="token string">r"C:\\Users\34538\Desktop\E题附件\附件2.测试数据\\"</span><span class="token operator">+</span>road<span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">".json"</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            txt<span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
            dicts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>txt

to_test_dict<span class="token punctuation">(</span>road_test<span class="token punctuation">,</span>test_data<span class="token punctuation">)</span>

test_sum<span class="token operator">=</span><span class="token number">0</span>
test_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    str_test <span class="token operator">=</span> test_data <span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> judge<span class="token punctuation">(</span><span class="token string">"authors"</span><span class="token punctuation">,</span> test_data <span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> judge<span class="token punctuation">(</span><span class="token string">"tittle"</span><span class="token punctuation">,</span> test_data <span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> str_test<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> str_test<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> str_test<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> removePunctuation<span class="token punctuation">(</span>str_test<span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> changePunctuation<span class="token punctuation">(</span>str_test<span class="token punctuation">)</span>
    test_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>str_test<span class="token punctuation">)</span>
    test_sum <span class="token operator">+=</span> <span class="token number">1</span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试数据总量为："</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_sum<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment">### 创建执行器</span>
place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CPUPlace<span class="token punctuation">(</span><span class="token punctuation">)</span>
infer_exe <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Executor<span class="token punctuation">(</span>place<span class="token punctuation">)</span>
infer_exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>default_startup_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

save_path <span class="token operator">=</span> <span class="token string">'C:\\Users\\34538\Desktop\E题附件\\'</span>

<span class="token punctuation">[</span>infer_program<span class="token punctuation">,</span> feeded_var_names<span class="token punctuation">,</span> target_var<span class="token punctuation">]</span> <span class="token operator">=</span> fluid<span class="token punctuation">.</span>io<span class="token punctuation">.</span>load_inference_model<span class="token punctuation">(</span>dirname<span class="token operator">=</span>save_path<span class="token punctuation">,</span> executor<span class="token operator">=</span>infer_exe<span class="token punctuation">)</span>


<span class="token comment">### 获取数据</span>
<span class="token keyword">def</span> <span class="token function">get_data</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 读取数据字典</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'C:\\Users\\34538\Desktop\E题附件\附件1.训练数据\\all_data\dict.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        dict_txt <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    dict_txt <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">)</span>
    <span class="token comment"># 把字符串数据转换成列表数据</span>
    keys <span class="token operator">=</span> dict_txt<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> s <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>
        <span class="token comment"># 判断是否存在未知字符</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> s <span class="token keyword">in</span> keys<span class="token punctuation">:</span>
            s <span class="token operator">=</span> <span class="token string">'&lt;unk&gt;'</span>
        data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">(</span>dict_txt<span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> data

data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token comment">### 获取全部测试数据</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>get_data<span class="token punctuation">(</span>removePunctuation<span class="token punctuation">(</span>test_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### 获取每句话的单词数量</span>
base_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> data<span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment">### 生成预测数据</span>

tensor_words <span class="token operator">=</span> fluid<span class="token punctuation">.</span>create_lod_tensor<span class="token punctuation">(</span>data<span class="token punctuation">,</span> base_shape<span class="token punctuation">,</span> place<span class="token punctuation">)</span>

<span class="token comment">### 执行预测</span>

result <span class="token operator">=</span> exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>program<span class="token operator">=</span>infer_program<span class="token punctuation">,</span>feed<span class="token operator">=</span><span class="token punctuation">{</span>feeded_var_names<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tensor_words<span class="token punctuation">}</span><span class="token punctuation">,</span>fetch_list<span class="token operator">=</span>target_var<span class="token punctuation">)</span>

names <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token string">'谣言'</span><span class="token punctuation">,</span> <span class="token string">'真新闻'</span><span class="token punctuation">]</span>

<span class="token comment">### 进行预测并评价预测结果</span>


<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    lab <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预测结果标签为：%d， 分类为：%s， 概率为：%f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>lab<span class="token punctuation">,</span> names<span class="token punctuation">[</span>lab<span class="token punctuation">]</span><span class="token punctuation">,</span> result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>lab<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>
        <div id="lv-container"></div>
        <div class="giscus"></div>
    </div>
</div>
<script type="text/javascript" src="https://cdn.lanluo.cn/js/canvas-nest.min.js"></script>
    </div>
</div>

<footer class="footer">
    <ul class="list-inline text-center">
        
        

        
        <li>
            <a target="_blank" href="http://weibo.com/2438257908">
                            <span class="fa-stack fa-lg">
                                  <i class="iconfont icon-weibo"></i>
                            </span>
            </a>
        </li>
        

        

        
        <li>
            <a target="_blank"  href="https://github.com/kmoonn">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-github"></i>
                            </span>
            </a>
        </li>
        

        

    </ul>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
    </p>
</footer>
<script type="text/javascript" src="https://cdn.lanluo.cn/js/canvas-nest.min.js"></script>
<script type="text/javascript" src="https://cdn.lanluo.cn/js/canvas-nest.min.js"></script>
<script type="text/javascript" src="https://cdn.lanluo.cn/js/canvas-nest.min.js"></script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":220,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/js/index.js"></script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>






</html>

<!DOCTYPE html><html lang="zh" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>数学建模-RNN卷积神经网络 | Kmoon_Hs</title><meta name="keywords" content="数学建模"><meta name="author" content="Kmoon,3453863492@qq.com"><meta name="copyright" content="Kmoon"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="### 导入必要的库 import json import os import random import re from multiprocessing import cpu_count import numpy as np import paddle import paddle.fluid as fluid paddle.enable_static() import matplotlib.py">
<meta property="og:type" content="article">
<meta property="og:title" content="数学建模-RNN卷积神经网络">
<meta property="og:url" content="http://www.kmoon.fun/2022/rnn/">
<meta property="og:site_name" content="Kmoon_Hs">
<meta property="og:description" content="### 导入必要的库 import json import os import random import re from multiprocessing import cpu_count import numpy as np import paddle import paddle.fluid as fluid paddle.enable_static() import matplotlib.py">
<meta property="og:locale">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2022-08-11T07:46:47.000Z">
<meta property="article:modified_time" content="2022-10-09T05:48:55.456Z">
<meta property="article:author" content="Kmoon">
<meta property="article:tag" content="数学建模">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://www.kmoon.fun/2022/rnn/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: [object Object]
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '数学建模-RNN卷积神经网络',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-10-09 13:48:55'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Kmoon_Hs" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Kmoon_Hs</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">数学建模-RNN卷积神经网络</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-08-11T07:46:47.000Z" title="Created 2022-08-11 15:46:47">2022-08-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-10-09T05:48:55.456Z" title="Updated 2022-10-09 13:48:55">2022-10-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Math/">Math</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="数学建模-RNN卷积神经网络"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">### 导入必要的库</span>
<span class="token keyword">import</span> json
<span class="token keyword">import</span> os
<span class="token keyword">import</span> random
<span class="token keyword">import</span> re
<span class="token keyword">from</span> multiprocessing <span class="token keyword">import</span> cpu_count
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> paddle
<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>fluid <span class="token keyword">as</span> fluid
paddle<span class="token punctuation">.</span>enable_static<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment">### 去除字符串的标点符号</span>
r<span class="token operator">=</span><span class="token string">'[’!"\'()+,-./:;&lt;=&gt;?@[\\]`{|}~\n。！，]+'</span>
<span class="token keyword">def</span> <span class="token function">removePunctuation</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    line<span class="token operator">=</span>re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">,</span>text<span class="token punctuation">)</span>
    <span class="token keyword">return</span> line

<span class="token comment">### 提取特殊符号</span>
s<span class="token operator">=</span><span class="token string">'…@#^&amp;*'</span>
<span class="token keyword">def</span> <span class="token function">changePunctuation</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> s<span class="token punctuation">:</span>
        <span class="token keyword">if</span> i <span class="token keyword">in</span> text<span class="token punctuation">:</span>
            text<span class="token operator">=</span>text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>s<span class="token punctuation">,</span><span class="token string">' '</span><span class="token operator">+</span>s<span class="token operator">+</span><span class="token string">' '</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> text
<span class="token comment">### 数据字典索引存在判断</span>
<span class="token keyword">def</span> <span class="token function">judge</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">,</span><span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">str</span> <span class="token keyword">in</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">str</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">""</span>
    
<span class="token comment">### 分别统计谣言数据与真新闻数据的总数</span>
rumor_num <span class="token operator">=</span> <span class="token number">0</span>
non_rumor_num <span class="token operator">=</span> <span class="token number">0</span>

all_rumor_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
all_non_rumor_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment">### 谣言标签为0，真新闻标签为1</span>
rumor_label <span class="token operator">=</span> <span class="token string">"0"</span>
non_rumor_label <span class="token operator">=</span> <span class="token string">"1"</span>

dicts_Fake<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token comment">#声明谣言字典</span>
dicts_Real<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token comment">#声明真新闻字典</span>
road_Fake<span class="token operator">=</span><span class="token string">"谣言\PolitiFact_Fake_"</span>     <span class="token comment">#谣言文件夹路径</span>
road_Real<span class="token operator">=</span><span class="token string">"真新闻\PolitiFact_Real_"</span>    <span class="token comment">#真新闻文件夹路径</span>

<span class="token comment">### 定义json转字典函数</span>
<span class="token keyword">def</span> <span class="token function">to_dict</span><span class="token punctuation">(</span>road<span class="token punctuation">,</span>dicts<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">111</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        filename<span class="token operator">=</span><span class="token string">r"C:\\Users\34538\Desktop\E题附件\附件1.训练数据\\"</span><span class="token operator">+</span>road<span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"-Webpage.json"</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            txt<span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
            dicts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>txt

<span class="token comment">### 构建谣言和真新闻字典</span>
to_dict<span class="token punctuation">(</span>road_Fake<span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">)</span>
to_dict<span class="token punctuation">(</span>road_Real<span class="token punctuation">,</span>dicts_Real<span class="token punctuation">)</span>

<span class="token comment">### 解析谣言和真新闻数据</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">111</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    str_Fake<span class="token operator">=</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"authors"</span><span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"tittle"</span><span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">'url'</span><span class="token punctuation">,</span>dicts_Fake<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>str_Fake<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>str_Fake<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>str_Fake<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>removePunctuation<span class="token punctuation">(</span>str_Fake<span class="token punctuation">)</span>
    str_Fake<span class="token operator">=</span>changePunctuation<span class="token punctuation">(</span>str_Fake<span class="token punctuation">)</span>
    all_rumor_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>rumor_label <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> str_Fake<span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>
    rumor_num <span class="token operator">+=</span> <span class="token number">1</span>
    str_Real<span class="token operator">=</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"authors"</span><span class="token punctuation">,</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">"tittle"</span><span class="token punctuation">,</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" "</span><span class="token operator">+</span>judge<span class="token punctuation">(</span><span class="token string">'url'</span><span class="token punctuation">,</span>dicts_Real<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>str_Real<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>str_Real<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>str_Real<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>removePunctuation<span class="token punctuation">(</span>str_Real<span class="token punctuation">)</span>
    str_Real<span class="token operator">=</span>changePunctuation<span class="token punctuation">(</span>str_Real<span class="token punctuation">)</span>
    all_non_rumor_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>non_rumor_label <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> str_Real<span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>
    non_rumor_num <span class="token operator">+=</span> <span class="token number">1</span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"谣言数据总量为："</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>rumor_num<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"真新闻数据总量为："</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>non_rumor_num<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### 全部数据进行乱序后写入all_data.txt</span>

data_list_path <span class="token operator">=</span> <span class="token string">"C:\\Users\\34538\Desktop\E题附件\附件1.训练数据\\all_data\\"</span>
all_data_path <span class="token operator">=</span> data_list_path <span class="token operator">+</span> <span class="token string">"all_data.txt"</span>

all_data_list <span class="token operator">=</span> all_rumor_list <span class="token operator">+</span> all_non_rumor_list

<span class="token comment">### 按随机数随机打乱数据</span>
random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>all_data_list<span class="token punctuation">)</span>

<span class="token comment">### 生成all_data.txt之前，首先将其清空</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> all_data_list<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token comment">### 生成数据字典</span>
<span class="token keyword">def</span> <span class="token function">create_dict</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> dict_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dict_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 读取全部数据</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 把数据生成一个元组</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
        content <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>
        removePunctuation<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
        <span class="token keyword">for</span> s <span class="token keyword">in</span> content<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            dict_set<span class="token punctuation">.</span>add<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
    <span class="token comment"># 把元组转换成字典，一个单词对应一个数字</span>
    dict_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    i <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> s <span class="token keyword">in</span> dict_set<span class="token punctuation">:</span>
        dict_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>s<span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        i <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token comment"># 添加未知字符</span>
    dict_txt <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>dict_list<span class="token punctuation">)</span>
    end_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"&lt;unk&gt;"</span><span class="token punctuation">:</span> i<span class="token punctuation">}</span>
    dict_txt<span class="token punctuation">.</span>update<span class="token punctuation">(</span>end_dict<span class="token punctuation">)</span>
    <span class="token comment"># 把这些字典保存到本地中</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"数据字典生成完成！"</span><span class="token punctuation">)</span>


<span class="token comment">### 获取字典的长度</span>
<span class="token keyword">def</span> <span class="token function">get_dict_len</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        line <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment">### 创建序列化表示的数据,</span>
<span class="token keyword">def</span> <span class="token function">create_data_list</span><span class="token punctuation">(</span>data_list_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 在生成数据之前，首先将train_list.txt清空</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'train_list.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_train<span class="token punctuation">:</span>
        f_train<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        f_train<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'dict.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        dict_txt <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'all_data.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    i <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'train_list.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_train<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">continue</span>
            words <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span>
            label <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            removePunctuation<span class="token punctuation">(</span>words<span class="token punctuation">)</span>
            labs <span class="token operator">=</span> <span class="token string">""</span>
            <span class="token keyword">for</span> s <span class="token keyword">in</span> words<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                lab <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>dict_txt <span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">)</span>
                labs <span class="token operator">=</span> labs <span class="token operator">+</span> lab <span class="token operator">+</span> <span class="token string">','</span>
            labs <span class="token operator">=</span> labs <span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
            labs <span class="token operator">=</span> labs <span class="token operator">+</span> <span class="token string">'\t'</span> <span class="token operator">+</span> label <span class="token operator">+</span> <span class="token string">'\n'</span>
            f_train<span class="token punctuation">.</span>write<span class="token punctuation">(</span>labs<span class="token punctuation">)</span>
            i <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"数据列表生成完成！"</span><span class="token punctuation">)</span>

<span class="token comment">### dict_path为数据字典存放路径</span>
dict_path <span class="token operator">=</span> data_list_path <span class="token operator">+</span> <span class="token string">"dict.txt"</span>

<span class="token comment">### 创建数据字典，存放位置：dict.txt。在生成之前先清空dict.txt</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span>
create_dict<span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> dict_path<span class="token punctuation">)</span>

<span class="token comment">### 创建数据列表，存放位置：train_list.txt</span>
create_data_list<span class="token punctuation">(</span>data_list_path<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">data_mapper</span><span class="token punctuation">(</span>sample<span class="token punctuation">)</span><span class="token punctuation">:</span>
    data<span class="token punctuation">,</span> label <span class="token operator">=</span> sample
    new_data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> i<span class="token punctuation">.</span>isdigit<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">continue</span>
        new_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> new_data<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span>

<span class="token comment">### 定义数据读取器</span>
<span class="token keyword">def</span> <span class="token function">data_reader</span><span class="token punctuation">(</span>data_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">reader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
                <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>
                data<span class="token punctuation">,</span> label <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
                <span class="token keyword">yield</span> data<span class="token punctuation">,</span> label
    <span class="token keyword">return</span> paddle<span class="token punctuation">.</span>reader<span class="token punctuation">.</span>xmap_readers<span class="token punctuation">(</span>data_mapper<span class="token punctuation">,</span> reader<span class="token punctuation">,</span> cpu_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>

<span class="token comment">### 获取训练数据读取器</span>
BATCH_SIZE <span class="token operator">=</span> <span class="token number">16</span> <span class="token comment">#维度参数设置</span>

train_list_path <span class="token operator">=</span> data_list_path<span class="token operator">+</span><span class="token string">'train_list.txt'</span>

train_reader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>
		reader<span class="token operator">=</span>data_reader<span class="token punctuation">(</span>train_list_path<span class="token punctuation">)</span><span class="token punctuation">,</span>
		batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">)</span>

<span class="token comment">### 定义长短期记忆网络</span>

<span class="token keyword">def</span> <span class="token function">lstm_net</span><span class="token punctuation">(</span>ipt<span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>

 <span class="token comment">#以数据的IDs作为输入</span>

emb <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>ipt<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">[</span>input_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span> is_sparse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># 第一个全连接层</span>

fc1 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>emb<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>

<span class="token comment">#进行一个长短期记忆操作</span>

lstm1<span class="token punctuation">,</span> _ <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dynamic_lstm<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>fc1<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>
<span class="token comment">#第一个最大序列池操作</span>
fc2 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>sequence_pool<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>fc1<span class="token punctuation">,</span> pool_type<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">)</span>
<span class="token comment">#第二个最大序列池操作</span>
lstm2 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>sequence_pool<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>lstm1<span class="token punctuation">,</span> pool_type<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">)</span>
<span class="token comment">#以softmax作为全连接的输出层，大小为2,也就是正负面</span>
out <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token punctuation">[</span>fc2<span class="token punctuation">,</span> lstm2<span class="token punctuation">]</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token keyword">return</span> out

<span class="token comment">### 定义输入数据， lod_level不为0指定输入数据为序列数据</span>
words <span class="token operator">=</span> fluid<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'words'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int64'</span><span class="token punctuation">,</span> lod_level<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
label <span class="token operator">=</span> fluid<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'label'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int64'</span><span class="token punctuation">)</span>

<span class="token comment">### 获取数据字典长度</span>
dict_dim <span class="token operator">=</span> get_dict_len<span class="token punctuation">(</span>dict_path<span class="token punctuation">)</span>
<span class="token comment">### 获取分类器</span>
model <span class="token operator">=</span> lstm_net<span class="token punctuation">(</span>words<span class="token punctuation">,</span> dict_dim<span class="token punctuation">)</span>

<span class="token comment">### 获取损失函数和准确率</span>
cost <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>model<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span>
avg_cost <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
acc <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>model<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span>

<span class="token comment">### 获取预测程序</span>
test_program <span class="token operator">=</span> fluid<span class="token punctuation">.</span>default_main_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clone<span class="token punctuation">(</span>for_test<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">### 定义优化方法</span>
optimizer <span class="token operator">=</span> fluid<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>AdagradOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
opt <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>avg_cost<span class="token punctuation">)</span>


use_cuda <span class="token operator">=</span> <span class="token boolean">False</span>
place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CUDAPlace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">if</span> use_cuda <span class="token keyword">else</span> fluid<span class="token punctuation">.</span>CPUPlace<span class="token punctuation">(</span><span class="token punctuation">)</span>
exe <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Executor<span class="token punctuation">(</span>place<span class="token punctuation">)</span>

<span class="token comment">### 进行参数初始化</span>
exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>default_startup_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### 定义数据映射器</span>
feeder <span class="token operator">=</span> fluid<span class="token punctuation">.</span>DataFeeder<span class="token punctuation">(</span>place<span class="token operator">=</span>place<span class="token punctuation">,</span> feed_list<span class="token operator">=</span><span class="token punctuation">[</span>words<span class="token punctuation">,</span> label<span class="token punctuation">]</span><span class="token punctuation">)</span>

all_train_iter<span class="token operator">=</span><span class="token number">0</span>
all_train_iters<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
all_train_costs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
all_train_accs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">draw_process</span><span class="token punctuation">(</span>title<span class="token punctuation">,</span>iters<span class="token punctuation">,</span>costs<span class="token punctuation">,</span>accs<span class="token punctuation">,</span>label_cost<span class="token punctuation">,</span>lable_acc<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>title<span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"iter"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"cost/acc"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>iters<span class="token punctuation">,</span> costs<span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span>label<span class="token operator">=</span>label_cost<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>iters<span class="token punctuation">,</span> accs<span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'green'</span><span class="token punctuation">,</span>label<span class="token operator">=</span>lable_acc<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


EPOCH_NUM <span class="token operator">=</span> <span class="token number">10</span>  <span class="token comment"># 训练轮数</span>
model_save_dir <span class="token operator">=</span> <span class="token string">'C:\\Users\\34538\Desktop\E题附件\\'</span>  
 <span class="token comment"># 模型保存路径</span>

<span class="token comment">### 开始训练</span>
<span class="token keyword">for</span> pass_id <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>EPOCH_NUM<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 进行训练</span>
    <span class="token keyword">for</span> batch_id<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_reader<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_cost<span class="token punctuation">,</span> train_acc <span class="token operator">=</span> exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>program<span class="token operator">=</span>fluid<span class="token punctuation">.</span>default_main_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        feed<span class="token operator">=</span>feeder<span class="token punctuation">.</span>feed<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        fetch_list<span class="token operator">=</span><span class="token punctuation">[</span>avg_cost<span class="token punctuation">,</span> acc<span class="token punctuation">]</span><span class="token punctuation">)</span>
        all_train_iter <span class="token operator">=</span> all_train_iter <span class="token operator">+</span> BATCH_SIZE
        all_train_iters<span class="token punctuation">.</span>append<span class="token punctuation">(</span>all_train_iter<span class="token punctuation">)</span>
        all_train_costs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_cost <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        all_train_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> batch_id <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Pass:%d, Batch:%d, Cost:%0.5f, Acc:%0.5f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>pass_id<span class="token punctuation">,</span> batch_id<span class="token punctuation">,</span> train_cost <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_acc <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### 保存模型</span>
<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>model_save_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>model_save_dir<span class="token punctuation">)</span>
fluid<span class="token punctuation">.</span>io<span class="token punctuation">.</span>save_inference_model<span class="token punctuation">(</span>model_save_dir<span class="token punctuation">,</span>
                              feeded_var_names<span class="token operator">=</span><span class="token punctuation">[</span>words<span class="token punctuation">.</span>name<span class="token punctuation">]</span><span class="token punctuation">,</span>
                              target_vars<span class="token operator">=</span><span class="token punctuation">[</span>model<span class="token punctuation">]</span><span class="token punctuation">,</span>
                              executor<span class="token operator">=</span>exe<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练模型保存完成！'</span><span class="token punctuation">)</span>

draw_process<span class="token punctuation">(</span><span class="token string">"train"</span><span class="token punctuation">,</span> all_train_iters<span class="token punctuation">,</span> all_train_costs<span class="token punctuation">,</span> all_train_accs<span class="token punctuation">,</span> <span class="token string">"trainning cost"</span><span class="token punctuation">,</span> <span class="token string">"trainning acc"</span><span class="token punctuation">)</span>

test_data<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>
road_test<span class="token operator">=</span><span class="token string">"test"</span>    <span class="token comment">#测试数据文件夹路径</span>

<span class="token comment">#定义json转字典函数</span>
<span class="token keyword">def</span> <span class="token function">to_test_dict</span><span class="token punctuation">(</span>road<span class="token punctuation">,</span>dicts<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        filename<span class="token operator">=</span><span class="token string">r"C:\\Users\34538\Desktop\E题附件\附件2.测试数据\\"</span><span class="token operator">+</span>road<span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">".json"</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            txt<span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
            dicts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>txt

to_test_dict<span class="token punctuation">(</span>road_test<span class="token punctuation">,</span>test_data<span class="token punctuation">)</span>

test_sum<span class="token operator">=</span><span class="token number">0</span>
test_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    str_test <span class="token operator">=</span> test_data <span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> judge<span class="token punctuation">(</span><span class="token string">"authors"</span><span class="token punctuation">,</span> test_data <span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> judge<span class="token punctuation">(</span><span class="token string">"tittle"</span><span class="token punctuation">,</span> test_data <span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> str_test<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> str_test<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> str_test<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> removePunctuation<span class="token punctuation">(</span>str_test<span class="token punctuation">)</span>
    str_test <span class="token operator">=</span> changePunctuation<span class="token punctuation">(</span>str_test<span class="token punctuation">)</span>
    test_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>str_test<span class="token punctuation">)</span>
    test_sum <span class="token operator">+=</span> <span class="token number">1</span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试数据总量为："</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_sum<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment">### 创建执行器</span>
place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CPUPlace<span class="token punctuation">(</span><span class="token punctuation">)</span>
infer_exe <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Executor<span class="token punctuation">(</span>place<span class="token punctuation">)</span>
infer_exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>default_startup_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

save_path <span class="token operator">=</span> <span class="token string">'C:\\Users\\34538\Desktop\E题附件\\'</span>

<span class="token punctuation">[</span>infer_program<span class="token punctuation">,</span> feeded_var_names<span class="token punctuation">,</span> target_var<span class="token punctuation">]</span> <span class="token operator">=</span> fluid<span class="token punctuation">.</span>io<span class="token punctuation">.</span>load_inference_model<span class="token punctuation">(</span>dirname<span class="token operator">=</span>save_path<span class="token punctuation">,</span> executor<span class="token operator">=</span>infer_exe<span class="token punctuation">)</span>


<span class="token comment">### 获取数据</span>
<span class="token keyword">def</span> <span class="token function">get_data</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 读取数据字典</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'C:\\Users\\34538\Desktop\E题附件\附件1.训练数据\\all_data\dict.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        dict_txt <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    dict_txt <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">)</span>
    <span class="token comment"># 把字符串数据转换成列表数据</span>
    keys <span class="token operator">=</span> dict_txt<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> s <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>
        <span class="token comment"># 判断是否存在未知字符</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> s <span class="token keyword">in</span> keys<span class="token punctuation">:</span>
            s <span class="token operator">=</span> <span class="token string">'&lt;unk&gt;'</span>
        data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">(</span>dict_txt<span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> data

data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token comment">### 获取全部测试数据</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>get_data<span class="token punctuation">(</span>removePunctuation<span class="token punctuation">(</span>test_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### 获取每句话的单词数量</span>
base_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> data<span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment">### 生成预测数据</span>

tensor_words <span class="token operator">=</span> fluid<span class="token punctuation">.</span>create_lod_tensor<span class="token punctuation">(</span>data<span class="token punctuation">,</span> base_shape<span class="token punctuation">,</span> place<span class="token punctuation">)</span>

<span class="token comment">### 执行预测</span>

result <span class="token operator">=</span> exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>program<span class="token operator">=</span>infer_program<span class="token punctuation">,</span>feed<span class="token operator">=</span><span class="token punctuation">{</span>feeded_var_names<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tensor_words<span class="token punctuation">}</span><span class="token punctuation">,</span>fetch_list<span class="token operator">=</span>target_var<span class="token punctuation">)</span>

names <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token string">'谣言'</span><span class="token punctuation">,</span> <span class="token string">'真新闻'</span><span class="token punctuation">]</span>

<span class="token comment">### 进行预测并评价预测结果</span>


<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    lab <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预测结果标签为：%d， 分类为：%s， 概率为：%f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>lab<span class="token punctuation">,</span> names<span class="token punctuation">[</span>lab<span class="token punctuation">]</span><span class="token punctuation">,</span> result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>lab<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://www.kmoon.fun">Kmoon</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://www.kmoon.fun/2022/rnn/">http://www.kmoon.fun/2022/rnn/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/">数学建模</a></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/xsslabs/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">靶场日记-XSSlabs</div></div></a></div><div class="next-post pull-right"><a href="/2022/gxds/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">数据库-关系代数语言</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Kmoon</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><a id="card-info-btn" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/jwtk/" title="WUT-计算机网络题库(86)"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="WUT-计算机网络题库(86)"/></a><div class="content"><a class="title" href="/2022/jwtk/" title="WUT-计算机网络题库(86)">WUT-计算机网络题库(86)</a><time datetime="2022-10-06T13:51:39.000Z" title="Created 2022-10-06 21:51:39">2022-10-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/software/" title="WUT-单片机EDA软件工具下载"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="WUT-单片机EDA软件工具下载"/></a><div class="content"><a class="title" href="/2022/software/" title="WUT-单片机EDA软件工具下载">WUT-单片机EDA软件工具下载</a><time datetime="2022-10-06T12:36:11.000Z" title="Created 2022-10-06 20:36:11">2022-10-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/networking/" title="WUT-组网技术实验报告"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="WUT-组网技术实验报告"/></a><div class="content"><a class="title" href="/2022/networking/" title="WUT-组网技术实验报告">WUT-组网技术实验报告</a><time datetime="2022-10-06T12:20:31.000Z" title="Created 2022-10-06 20:20:31">2022-10-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/xue-xi-zha-ji-linux-ji-chu-ru-men/" title="学习札记—Linux基础入门"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="学习札记—Linux基础入门"/></a><div class="content"><a class="title" href="/2022/xue-xi-zha-ji-linux-ji-chu-ru-men/" title="学习札记—Linux基础入门">学习札记—Linux基础入门</a><time datetime="2022-10-06T09:54:11.000Z" title="Created 2022-10-06 17:54:11">2022-10-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/51dpj/" title="学习札记——51单片机(C语言版)"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="学习札记——51单片机(C语言版)"/></a><div class="content"><a class="title" href="/2022/51dpj/" title="学习札记——51单片机(C语言版)">学习札记——51单片机(C语言版)</a><time datetime="2022-09-27T10:52:12.000Z" title="Created 2022-09-27 18:52:12">2022-09-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Kmoon</div><div class="framework-info"><span>Framework </span><a href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":250,"height":350},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>